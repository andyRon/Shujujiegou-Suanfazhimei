## 5-数组：为什么很多编程语言中数组都从0开始编号？ 

 

### 如何实现随机访问？

**数组（Array）是一种<font color=#FF8C00>线性表</font>数据结构。它用一组<font color=#FF8C00>连续的内存空间</font>，来存储一组具有<font color=#FF8C00>相同类型</font>的数据。** 

- **<font color=#FF8C00>线性表（Linear List）</font>**就是数据排成像一条线一样的结构。每个线性表上的数据最多只有**前和后**两个方向。其实除了<font color=#FF8C00>数组，链表、队列、栈</font>等也是线性表结构。 

<img src="images/SJJG+SFZM-05-01.jpg" style="zoom:50%;" />

- **<font color=#FF8C00>非线性表</font>**，比如<font color=#FF8C00>二叉树、堆、图</font>等。在非线性表中，数据之间并不是简单的**前后关系**。

<img src="images/SJJG+SFZM-05-02.jpg" style="zoom:50%;" />

- <font color=#FF8C00>连续的内存空间和相同类型的数据</font>。

  利：“**随机访问**”。

  弊：很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。 

#### 数组是如何实现根据下标随机访问数组元素的吗？

我们拿一个长度为 10 的 int 类型的数组 `int[] a = new int[10]` 来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。 

<img src="images/SJJG+SFZM-05-03.jpg" style="zoom:50%;" />

我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址： 


```java
a[i]_address = base_address + i * data_type_size 
```


其中 **data_type_size** 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。 

#### 数组和链表的区别？

不准确表达，“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”。 

数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，**<font color=#FF8C00>数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)</font>**。 



### 低效的“插入”和“删除”

数组为了保持内存数据的连续性，会导致插入、删除比较低效。

#### **插入操作** 

假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。那插入操作的时间复杂度是多少呢？

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。 

如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数组插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，**直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。** 

为了更好地理解，我们举一个例子。假设数组 a[10] 中存储了如下 5 个元素：a，b，c，d，e。 

我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a[5]，将 a[2] 赋值为 x 即可。最后，数组中的元素如下： a，b，x，d，e，c。 

![](images/SJJG+SFZM-05-04.jpg)

利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在快排中也会用到。 

#### **删除操作**

跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。 

和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。 

实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们**将多次删除操作集中在一起执行**，删除的效率是不是会提高很多呢？ 

我们继续来看例子。数组 a[10] 中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。 

![](images/SJJG+SFZM-05-05.jpg)



为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。 

如果你了解 **JVM**(JAVAV虚拟机)，你会发现，这不就是**JVM标记清除垃圾回收算法**的核心思想吗？没错，数据结构和算法的魅力就在于此，<font color=#FF8C00>很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的</font>。如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。 

### 警惕数组的访问越界问题

> 在C语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。

很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统。

`java.lang.ArrayIndexOutOfBoundsException`

### 容器能否完全替代数组？

Java中`ArrayList`的优势：**将很多数组操作（比如插入、删除等）的细节封装起来**；**支持动态扩容**。

最好在创建 ArrayList 的时候事先指定数据大小。事先指定数据大小可以省掉很多次内存申请和数据搬移操作。

数组更适合的情况：

1. ArrayList无法存储基本类型，需要封装为包装类；
2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。
3. 多维数组时，用数组往往会更加直观

```java
Object[][] array;
  
ArrayList<ArrayList<Object>> array;
```

总结：对于业务开发，直接使用容器就足够了。一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器。



### 为什么很多编程语言中数组都从0开始编号？

原因一：”下标“理解为”偏移（offset）“，从1开始，对CPU来说，就多了一次减法指令。

```c
a[k]_address = base_address + k * type_size

a[k]_address = base_address + (k-1)*type_size
```

原因二：历史原因。C语言设计者用 0 开始计数数组下标。



### 课后思考

1. 前面我基于数组的原理引出 **JVM的标记清除垃圾回收算法**的核心理念。那怎么理解的标记清除垃圾回收算法。 

   大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

   不足：1.效率问题。标记和清理效率都不高，但是当知道只有少量垃圾产生时会很高效。2.空间问题。会产生不连续的内存空间碎片。

2. 前面我们讲到一维数组的内存寻址公式，那你可以思考一下，类比一下，二维数组的内存寻址公式是怎样的呢？ 

   对于 m * n 的数组，`a [i][j]` (i < m,j < n)的地址为：`address = base_address + ( i * n + j) * type_size`
